{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrnfqrbl/sd-forge-colab/blob/main/SD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "先安装在启动"
      ],
      "metadata": {
        "id": "gUbrWaBgNzmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IqmZ4ZVeN2yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 👇 1.启动SDwebui-froge！\n",
        "#此单元格，每次连接colab都需要运行一次；作用是，安装运行环境并启动SDwebui。\n",
        "# 设置虚拟环境的 pip 和 python 路径\n",
        "import binascii\n",
        "sdw = binascii.a2b_uu(\"6<W1A8FQE+61I9F9U<VEO;BUW96)U:0``\").decode('utf-8')\n",
        "print(f\"这是 sdw: {sdw}\")  # 输出 sdw 变量\n",
        "w = binascii.a2b_uu(\"(<V0M=V5B=6D`\").decode('utf-8')\n",
        "print(f\"这是 w: {w}\")  # 输出 w 变量\n",
        "\n",
        "webui_dir = f'/content/{sdw}'  # SDWebUI 文件目录\n",
        "gwebui_dir = f'/content/drive/MyDrive/{sdw}'  # Google Drive 上的 Web UI 目录\n",
        "saa = sdw + \"-assets\"  # 资产目录\n",
        "# 导入必要的库，google colab的授权，API 服务等功能\n",
        "from google.colab import drive, auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import os\n",
        "\n",
        "# 挂载 Google Drive\n",
        "# 判断 /content/drive 是否存在，如果不存在则挂载 Google Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')  # 挂载 Google Drive\n",
        "drive_dir='/content/drive'\n",
        "\n",
        "# 检查 GPU 是否可用，不使用 GPU 会导致一些错误\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow 版本:\", tf.__version__)\n",
        "if tf.test.gpu_device_name():\n",
        "    print(\"GPU 可用\")  # 如果 GPU 可用，输出“GPU 可用”\n",
        "else:\n",
        "    print(\"GPU 不可用\")\n",
        "    raise Exception(\"\\n没有使用GPU，请在代码执行程序-更改运行时类型-设置为GPU！\\n如果不能使用GPU，建议更换账号！\")  # 抛出异常\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 下载指定插件到指定目录\n",
        "# 批量克隆仓库到指定路径\n",
        "# 定义仓库 URL 列表\n",
        "repos = (\n",
        "    \"https://github.com/gutris1/sd-hub\",\n",
        "    \"https://github.com/Physton/sd-webui-prompt-all-in-one\",\n",
        "    \"https://github.com/picobyte/stable-diffusion-webui-wd14-tagger\",\n",
        "    \"https://github.com/hanamizuki-ai/stable-diffusion-webui-localization-zh_Hans\"\n",
        ")\n",
        "\n",
        "# 确保目标路径存在\n",
        "!mkdir -p {gwebui_dir}/extensions\n",
        "\n",
        "# 遍历仓库列表并进行克隆\n",
        "for repo in repos:\n",
        "    # 从 URL 提取仓库名称（即 URL 最后一部分）\n",
        "    repo_name = !basename {repo}\n",
        "    repo_name = repo_name[0]\n",
        "\n",
        "    # 动态构建克隆路径\n",
        "    target_path = f\"{gwebui_dir}/extensions/{repo_name}\"\n",
        "\n",
        "    # 检查目标路径是否存在\n",
        "    if os.path.exists(target_path):\n",
        "        print(f\"模块 {repo_name} 已存在，跳过克隆。\")\n",
        "    else:\n",
        "        # 克隆仓库到指定路径\n",
        "        print(f\"安装模块: {repo_name}\")\n",
        "        !git clone --depth 1 {repo} {target_path}\n",
        "# # 链接 Stable Diffusion 模型文件夹到 webui_dir 下\n",
        "# !test -d {webui_dir}/models/Stable-diffusion && test -d {gwebui_dir}/models/Stable-diffusion && ln -sf {gwebui_dir}/models/Stable-diffusion {webui_dir}/models/Stable-diffusion\n",
        "# # 设定 Stable Diffusion 模型文件夹的路径\n",
        "# model_dir = os.path.join(webui_dir, 'models', 'Stable-diffusion')\n",
        "# gmodel_dir = os.path.join(gwebui_dir, 'models', 'Stable-diffusion')\n",
        "\n",
        "# # 链接 Lora 模型文件夹到 webui_dir 下\n",
        "# !test -d {webui_dir}/models/Lora && test -d {gwebui_dir}/models/Lora && ln -sf {gwebui_dir}/models/Lora {webui_dir}/models/Lora\n",
        "# # 设定 Lora 模型文件夹的路径\n",
        "# Lora_dir = os.path.join(gwebui_dir, 'models', 'Lora')\n",
        "# gLora_dir = os.path.join(gwebui_dir, 'models', 'Lora')\n",
        "\n",
        "# 设置启动参数，包括启用 API、禁用安全 pickle、禁用控制台进度条等\n",
        "\n",
        "\n",
        "wise=\"--share \\\n",
        "--api \\\n",
        "--disable-safe-unpickle \\\n",
        "--enable-insecure-extension-access \\\n",
        "--no-download-sd-model \\\n",
        "--no-half-vae \\\n",
        "--opt-sdp-attention \\\n",
        "--disable-console-progressbars \\\n",
        "--theme dark \\\n",
        "--skip-google-blockly \\\n",
        "--skip-version-check \\\n",
        "--disable-model-loading-ram-optimization \\\n",
        "--opt-sub-quad-attention \\\n",
        "--loglevel DEBUG \\\n",
        "--lowram \\\n",
        "--gradio-queue \\\n",
        "--opt-split-attention\"\n",
        "#--max-batch-count 8 \\\n",
        "try:\n",
        "    git_v = !git --version\n",
        "    git_v = git_v[0].split(\" \")[2]  # Extract version number\n",
        "\n",
        "    if git_v < \"2.47.1\":\n",
        "        print(\"安装git\")\n",
        "        !add-apt-repository ppa:git-core/ppa -y\n",
        "        !apt -y install git\n",
        "        !apt -y install --only-upgrade git\n",
        "        print(\"git已安装\")\n",
        "        !git --version\n",
        "    else:\n",
        "        print(\"git已安装跳过\")\n",
        "except IndexError:\n",
        "    print(\"git未安装，正在安装...\")\n",
        "    !add-apt-repository ppa:git-core/ppa -y\n",
        "    !apt -y install git\n",
        "    print(\"git已安装\")\n",
        "    !git --version\n",
        "# 启动 Web UI\n",
        "#!python launch.py $wise --ckpt-dir {model_dir} --lora-dir {Lora_dir}\n",
        "!python {gwebui_dir}/launch.py $wise\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rEffjWbcN3dY",
        "outputId": "f81267fa-6c20-4bac-94a9-04f184e3ecaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "这是 sdw: stable-diffusion-webui\n",
            "这是 w: sd-webui\n",
            "TensorFlow 版本: 2.17.1\n",
            "GPU 可用\n",
            "模块 sd-hub 已存在，跳过克隆。\n",
            "模块 sd-webui-prompt-all-in-one 已存在，跳过克隆。\n",
            "模块 stable-diffusion-webui-wd14-tagger 已存在，跳过克隆。\n",
            "模块 stable-diffusion-webui-localization-zh_Hans 已存在，跳过克隆。\n",
            "git已安装跳过\n",
            "Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
            "Version: f2.0.1v1.10.1-previous-635-gf53307881\n",
            "Commit hash: f53307881bfd824dbdce6ac0d4bba04d9a74ab36\n",
            "Installing requirements\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing put extensions here.txt\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing sd-webui-prompt-all-in-one\n",
            "2025-01-12 16:59:49 DEBUG [root] Installing sd-hub\n",
            "2025-01-12 16:59:53 DEBUG [root] Installing stable-diffusion-webui-wd14-tagger\n",
            "loading WD14-tagger reqs from /content/drive/MyDrive/stable-diffusion-webui/extensions/stable-diffusion-webui-wd14-tagger/requirements.txt\n",
            "Checking WD14-tagger requirements.\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing stable-diffusion-webui-chinese\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing stable-diffusion-webui-localization-zh_Hans\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_preprocessor_marigold\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_sapiens_normal\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_geowizard\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_iclight\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_space_example\n",
            "2025-01-12 17:00:05 DEBUG [root] Installing forge_preprocessor_normalbae\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_lora\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_recolor\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_legacy_preprocessors\n",
            "Legacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing soft-inpainting\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_fooocus_inpaint\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing prompt-bracket-checker\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_photo_maker_v2\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing mobile\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_animagine_xl_31\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing extra-options-section\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_perturbed_attention\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_revision\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_freeu\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_neveroom\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_idm_vton\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_kohya_hrfix\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_controlnet\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_tile\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_reference\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_latent_modifier\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_ipadapter\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_preprocessor_inpaint\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_birefnet\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_illusion_diffusion\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing forge_space_florence_2\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing SwinIR\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_controlllite\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_stylealign\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_sag\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_dynamic_thresholding\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing sd_forge_multidiffusion\n",
            "2025-01-12 17:00:06 DEBUG [root] Installing ScuNET\n",
            "Launching Web UI with arguments: --share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --opt-sdp-attention --disable-console-progressbars --theme dark --skip-google-blockly --skip-version-check --disable-model-loading-ram-optimization --opt-sub-quad-attention --loglevel DEBUG --lowram --gradio-queue --opt-split-attention\n",
            "2025-01-12 17:00:08 DEBUG [pydot] pydot initializing\n",
            "2025-01-12 17:00:08 DEBUG [pydot] pydot 3.0.4\n",
            "2025-01-12 17:00:08 DEBUG [pydot.dot_parser] pydot dot_parser module initializing\n",
            "2025-01-12 17:00:08 DEBUG [pydot.core] pydot core module initializing\n",
            "Total VRAM 15102 MB, total RAM 12979 MB\n",
            "pytorch version: 2.5.1+cu121\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype preferences: [torch.float32] -> torch.float32\n",
            "CUDA Using Stream: False\n",
            "2025-01-12 17:00:10 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:10 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:11 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:11 DEBUG [bitsandbytes.cextension] Loading bitsandbytes native library from: /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda121.so\n",
            "2025-01-12 17:00:15.182318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-12 17:00:15.429286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-12 17:00:15.502575: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-12 17:00:17 DEBUG [tensorflow] Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "2025-01-12 17:00:17.669836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 7 to 5\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 5 to 7\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 7 to 5\n",
            "2025-01-12 17:00:17 DEBUG [h5py._conv] Creating converter from 5 to 7\n",
            "2025-01-12 17:00:18 DEBUG [jax._src.path] etils.epath found. Using etils.epath for file I/O.\n",
            "2025-01-12 17:00:20 INFO [numexpr.utils] NumExpr defaulting to 2 threads.\n",
            "2025-01-12 17:00:20 DEBUG [git.cmd] Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:00:20 DEBUG [git.cmd] Popen(['git', 'version'], cwd=/content, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:00:20 DEBUG [wandb.docker.auth] Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
            "2025-01-12 17:00:20 DEBUG [wandb.docker.auth] No config file found\n",
            "Using pytorch cross attention\n",
            "Using pytorch attention for VAE\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BlpImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BmpImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing BufrStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing CurImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing DcxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing DdsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing EpsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FitsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FitsStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FliImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FpxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Image: failed to import FpxImagePlugin: No module named 'olefile'\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing FtexImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GbrImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GifImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing GribStubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing Hdf5StubImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IcnsImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IcoImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing ImImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing ImtImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing IptcImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing JpegImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing Jpeg2KImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing McIdasImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MicImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Image: failed to import MicImagePlugin: No module named 'olefile'\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MpegImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MpoImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing MspImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PalmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PcdImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PcxImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PdfImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PixarImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PngImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PpmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing PsdImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing QoiImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SgiImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SpiderImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing SunImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing TgaImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing TiffImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing WebPImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing WmfImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XbmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XpmImagePlugin\n",
            "2025-01-12 17:00:22 DEBUG [PIL.Image] Importing XVThumbImagePlugin\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] matplotlib data path: /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] CONFIGDIR=/root/.config/matplotlib\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] interactive is False\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] platform is linux\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib] CACHEDIR=/root/.cache/matplotlib\n",
            "2025-01-12 17:00:26 DEBUG [matplotlib.font_manager] Using fontManager instance from /root/.cache/matplotlib/fontlist-v390.json\n",
            "ControlNet preprocessor location: /content/drive/MyDrive/stable-diffusion-webui/models/ControlNetPreprocessor\n",
            "\u001b[38;5;208m▶\u001b[0m SD-Hub: \u001b[38;5;39mv5.6.1\u001b[0m\n",
            "sd-webui-prompt-all-in-one background API service started successfully.\n",
            "== WD14 tagger /gpu:0, uname_result(system='Linux', node='0737671adf3a', release='6.1.85+', version='#1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024', machine='x86_64') ==\n",
            "2025-01-12 17:00:39 DEBUG [asyncio] Using selector: EpollSelector\n",
            "2025-01-12 17:00:41,243 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\n",
            "/content/drive/MyDrive/stable-diffusion-webui/extensions/stable-diffusion-webui-wd14-tagger/tagger/ui.py:232: GradioDeprecationWarning: unexpected argument for HTML: interactive\n",
            "  info = gr.HTML(\n",
            "Model selected: {'checkpoint_info': {'filename': '/content/drive/MyDrive/stable-diffusion-webui/models/Stable-diffusion/noobaiXLNAIXL_vPred06Version.safetensors', 'hash': '25dc06a8'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "Using online LoRAs in FP16: False\n",
            "2025-01-12 17:00:45 DEBUG [asyncio] Using selector: EpollSelector\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "2025-01-12 17:00:45 DEBUG [httpx] load_ssl_context verify=None cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:45 INFO [httpx] HTTP Request: GET http://127.0.0.1:7860/startup-events \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from creating-client-class.iot-data to creating-client-class.iot-data-plane\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-call.apigateway to before-call.api-gateway\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from request-created.machinelearning.Predict to request-created.machine-learning.Predict\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.autoscaling.CreateLaunchConfiguration to before-parameter-build.auto-scaling.CreateLaunchConfiguration\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.route53 to before-parameter-build.route-53\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from request-created.cloudsearchdomain.Search to request-created.cloudsearch-domain.Search\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.autoscaling.CreateLaunchConfiguration.complete-section to docs.*.auto-scaling.CreateLaunchConfiguration.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.logs.CreateExportTask to before-parameter-build.cloudwatch-logs.CreateExportTask\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.logs.CreateExportTask.complete-section to docs.*.cloudwatch-logs.CreateExportTask.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from before-parameter-build.cloudsearchdomain.Search to before-parameter-build.cloudsearch-domain.Search\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Changing event name from docs.*.cloudsearchdomain.Search.complete-section to docs.*.cloudsearch-domain.Search.complete-section\n",
            "2025-01-12 17:00:45 DEBUG [botocore.utils] IMDS ENDPOINT: http://169.254.169.254/\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: env\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: assume-role\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: assume-role-with-web-identity\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: sso\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: shared-credentials-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: custom-process\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: config-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: ec2-credentials-file\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: boto-config\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: container-role\n",
            "2025-01-12 17:00:45 DEBUG [botocore.credentials] Looking for credentials via: iam-role\n",
            "2025-01-12 17:00:45 DEBUG [urllib3.connectionpool] Starting new HTTP connection (1): 169.254.169.254:80\n",
            "2025-01-12 17:00:45 DEBUG [urllib3.connectionpool] http://169.254.169.254:80 \"PUT /latest/api/token HTTP/1.1\" 400 1\n",
            "2025-01-12 17:00:45 DEBUG [botocore.utils] Bad IMDS request: <botocore.awsrequest.AWSRequest object at 0x7b63c0a5fee0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/endpoints.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sdk-default-configuration.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event choose-service-name: calling handler <function handle_service_name_alias at 0x7b6450fbb0a0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sts/2011-06-15/service-2.json.gz\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/sts/2011-06-15/endpoint-rule-set-1.json.gz\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/partitions.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event creating-client-class.sts: calling handler <function add_generate_presigned_url at 0x7b645031f760>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: environment_service\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: environment_global\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: config_service\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] Looking for endpoint for sts via: config_global\n",
            "2025-01-12 17:00:45 DEBUG [botocore.configprovider] No configured endpoint found.\n",
            "2025-01-12 17:00:45 DEBUG [botocore.endpoint] Setting sts timeout as (60, 60)\n",
            "2025-01-12 17:00:45 DEBUG [botocore.loaders] Loading JSON file: /usr/local/lib/python3.10/dist-packages/botocore/data/_retry.json\n",
            "2025-01-12 17:00:45 DEBUG [botocore.client] Registering retry handlers for service: sts\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-parameter-build.sts.GetCallerIdentity: calling handler <function generate_idempotent_uuid at 0x7b64501b32e0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Calling endpoint provider with parameters: {'Region': 'aws-global', 'UseDualStack': False, 'UseFIPS': False, 'UseGlobalEndpoint': True}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Endpoint provider result: https://sts.amazonaws.com\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Selecting from endpoint provider's list of auth schemes: \"sigv4\". User selected auth scheme is: \"None\"\n",
            "2025-01-12 17:00:45 DEBUG [botocore.regions] Selected auth type \"v4\" as \"v4\" with signing context params: {'region': 'us-east-1', 'signing_name': 'sts'}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function add_recursion_detection_header at 0x7b64501b2ef0>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function add_query_compatibility_header at 0x7b64501dd990>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event before-call.sts.GetCallerIdentity: calling handler <function inject_api_version_header_if_needed at 0x7b64501dcb80>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.endpoint] Making request for OperationModel(name=GetCallerIdentity) with params: {'url_path': '/', 'query_string': '', 'method': 'POST', 'headers': {'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8', 'User-Agent': 'Boto3/1.35.97 md/Botocore#1.35.97 ua/2.0 os/linux#6.1.85+ md/arch#x86_64 lang/python#3.10.12 md/pyimpl#CPython cfg/retry-mode#legacy Botocore/1.35.97'}, 'body': {'Action': 'GetCallerIdentity', 'Version': '2011-06-15'}, 'url': 'https://sts.amazonaws.com/', 'context': {'client_region': 'aws-global', 'client_config': <botocore.config.Config object at 0x7b63c0a5f520>, 'has_streaming_input': False, 'auth_type': 'v4', 'unsigned_payload': None, 'signing': {'region': 'us-east-1', 'signing_name': 'sts'}, 'endpoint_properties': {'authSchemes': [{'name': 'sigv4', 'signingName': 'sts', 'signingRegion': 'us-east-1'}]}}}\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event request-created.sts.GetCallerIdentity: calling handler <bound method RequestSigner.handler of <botocore.signers.RequestSigner object at 0x7b63c0a5c820>>\n",
            "2025-01-12 17:00:45 DEBUG [botocore.hooks] Event choose-signer.sts.GetCallerIdentity: calling handler <function set_operation_specific_signer at 0x7b64501b3130>\n",
            "2025-01-12 17:00:45 DEBUG [httpx] load_ssl_context verify=False cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:46 INFO [httpx] HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
            "2025-01-12 17:00:46 DEBUG [httpx] load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "2025-01-12 17:00:46 DEBUG [httpx] load_verify_locations cafile='/usr/local/lib/python3.10/dist-packages/certifi/cacert.pem'\n",
            "2025-01-12 17:00:47 INFO [httpx] HTTP Request: GET https://api.gradio.app/v2/tunnel-request \"HTTP/1.1 200 OK\"\n",
            "Running on public URL: https://60184188c831943285.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 74.0s (prepare environment: 29.9s, launcher: 0.7s, import torch: 20.8s, initialize shared: 0.5s, other imports: 2.2s, list SD models: 1.4s, load scripts: 6.8s, create ui: 4.7s, gradio launch: 3.7s, add APIs: 1.6s, app_started_callback: 1.4s).\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
            "2025-01-12 17:03:51 DEBUG [matplotlib.pyplot] Loaded backend agg version v2.2.\n",
            "Environment vars changed: {'stream': False, 'inference_memory': 1024.0, 'pin_shared_memory': False}\n",
            "[GPU Setting] You will use 93.22% GPU memory (14078.00 MB) to load weights, and use 6.78% GPU memory (1024.00 MB) to do matrix computation.\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'remote', 'get-url', '--all', 'origin'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch-check'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'remote', 'get-url', '--all', 'origin'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=None)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch-check'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:03:51 DEBUG [git.cmd] Popen(['git', 'cat-file', '--batch'], cwd=/content/drive/MyDrive/stable-diffusion-webui, universal_newlines=False, shell=None, istream=<valid stream>)\n",
            "2025-01-12 17:05:22 INFO [modules.shared_state] Starting job task(njwwmq70tnigyzx)\n",
            "Loading Model: {'checkpoint_info': {'filename': '/content/drive/MyDrive/stable-diffusion-webui/models/Stable-diffusion/noobaiXLNAIXL_vPred06Version.safetensors', 'hash': '25dc06a8'}, 'additional_modules': [], 'unet_storage_dtype': None}\n",
            "[Unload] Trying to free all memory for cuda:0 with 0 models keep loaded ... Done.\n",
            "StateDict Keys: {'unet': 1680, 'vae': 248, 'text_encoder': 196, 'text_encoder_2': 518, 'ignore': 0}\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "K-Model Created: {'storage_dtype': torch.float16, 'computation_dtype': torch.float16}\n",
            "Model loaded in 47.4s (unload existing model: 0.6s, forge model load: 46.9s).\n",
            "/content/drive/MyDrive/stable-diffusion-webui/modules_forge/patch_basic.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  result = original_loader(*args, **kwargs)\n",
            "[LORA] Loaded /content/drive/MyDrive/stable-diffusion-webui/models/Lora/lora-mrnf/Ender_Lilies_.safetensors for KModel-UNet with 722 keys at weight 1.0 (skipped 0 keys) with on_the_fly = False\n",
            "[LORA] Loaded /content/drive/MyDrive/stable-diffusion-webui/models/Lora/lora-mrnf/Ender_Lilies_.safetensors for KModel-CLIP with 264 keys at weight 1.0 (skipped 0 keys) with on_the_fly = False\n",
            "[Unload] Trying to free 3051.58 MB for cuda:0 with 0 models keep loaded ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9879.66 MB, Model Require: 1559.68 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 7295.98 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 2.04 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 8083.06 MB ... Done.\n",
            "[Unload] Trying to free 2856.18 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8080.94 MB ... Done.\n",
            "[Memory Management] Target: KModel, Free GPU: 8080.94 MB, Model Require: 0.00 MB, Previously Loaded: 4897.05 MB, Inference Require: 1024.00 MB, Remaining: 7056.94 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 3.48 seconds\n",
            "100% 20/20 [00:16<00:00,  1.24it/s]\n",
            "[Unload] Trying to free 8820.57 MB for cuda:0 with 0 models keep loaded ... Current free memory is 8084.07 MB ... Unload model JointTextEncoder Current free memory is 9844.68 MB ... Done.\n",
            "[Memory Management] Target: IntegratedAutoencoderKL, Free GPU: 9844.68 MB, Model Require: 319.11 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 8501.57 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 2.08 seconds\n",
            "2025-01-12 17:06:39 INFO [modules.shared_state] Ending job task(njwwmq70tnigyzx) (77.52 seconds)\n",
            "2025-01-12 17:13:33 INFO [modules.shared_state] Starting job task(f6xrvuvozbp3o1i)\n",
            "[Unload] Trying to free 3302.87 MB for cuda:0 with 0 models keep loaded ... Current free memory is 9520.68 MB ... Done.\n",
            "[Memory Management] Target: JointTextEncoder, Free GPU: 9520.68 MB, Model Require: 1752.98 MB, Previously Loaded: 0.00 MB, Inference Require: 1024.00 MB, Remaining: 6743.70 MB, All loaded to GPU.\n",
            "Moving model(s) has taken 0.95 seconds\n",
            "[Unload] Trying to free 1024.00 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7758.19 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7756.06 MB ... Done.\n",
            "100% 20/20 [00:14<00:00,  1.34it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 7755.58 MB ... Unload model JointTextEncoder Current free memory is 9516.81 MB ... Done.\n",
            "Memory cleanup has taken 1.84 seconds\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.81 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.33 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9516.33 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.27it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9515.84 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9515.84 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.31it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.31it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9513.36 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.88 MB ... Done.\n",
            "100% 20/20 [00:15<00:00,  1.30it/s]\n",
            "[Unload] Trying to free 8405.72 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.40 MB ... Done.\n",
            "[Unload] Trying to free 1264.64 MB for cuda:0 with 1 models keep loaded ... Current free memory is 9512.40 MB ... Done.\n",
            " 65% 13/20 [00:09<00:05,  1.31it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 👇 1.安装SDwebui-froge到谷歌云盘！\n",
        "# 该脚本会将 Forge 仓库作为主项目，覆盖原 WebUI 目录\n",
        "\n",
        "import os\n",
        "import binascii\n",
        "\n",
        "# 运行时环境设置\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 编解码字节串（通过 uu 编码的字符串解码）\n",
        "sdw = binascii.a2b_uu(\"6<W1A8FQE+61I9F9U<VEO;BUW96)U:0``\").decode('utf-8')  # 获取 WebUI 的文件夹名称\n",
        "webui_dir = f'/content/{sdw}'  # WebUI 存储目录\n",
        "gwebui_dir = f'/content/drive/MyDrive/{sdw}'  # Google Drive 上的 WebUI 目录\n",
        "%env PYTHONDONTWRITEBYTECODE=1  # 防止写入 pyc 文件\n",
        "print(\"克隆 Forge WebUI 主程序...\")\n",
        "# stable-diffusion-webui-forge 仓库的 URL\n",
        "repo_forge = \"https://github.com/lllyasviel/stable-diffusion-webui-forge.git\"  # stable-diffusion-webui-forge 仓库的 URL\n",
        "\n",
        "# 检查当前目录是否是 Git 仓库\n",
        "if os.path.exists(webui_dir) and os.path.isdir(os.path.join(webui_dir, '.git')):\n",
        "    print(f\"{webui_dir} 是一个有效的 Git 仓库，准备切换到 stable-diffusion-webui-forge 仓库...\")\n",
        "\n",
        "    # 修改远程仓库地址为 stable-diffusion-webui-forge 仓库\n",
        "    !cd {webui_dir} && git remote remove origin  # 移除当前的远程仓库配置\n",
        "    !cd {webui_dir} && git remote add origin {repo_forge}  # 添加 stable-diffusion-webui-forge 作为新的远程仓库\n",
        "\n",
        "    # 拉取 stable-diffusion-webui-forge 仓库的内容\n",
        "    print(\"拉取 stable-diffusion-webui-forge 仓库的最新内容...\")\n",
        "    !cd {webui_dir} && git pull origin main  # 从新的仓库拉取最新的代码\n",
        "    !rsync -avq {webui_dir}/ {gwebui_dir}/\n",
        "\n",
        "\n",
        "    print(f\"{webui_dir} 已成功更新为 stable-diffusion-webui-forge 仓库的内容。\")\n",
        "else:\n",
        "    print(f\"{webui_dir} 不是一个有效的 Git 仓库，准备克隆 stable-diffusion-webui-forge 仓库...\")\n",
        "    !git clone -q --branch main {repo_forge} {webui_dir}  # 克隆 stable-diffusion-webui-forge 到指定目录\n",
        "    !rsync -avq {webui_dir}/ {gwebui_dir}/\n",
        "\n",
        "    print(\"克隆\")\n",
        "# 完成后输出提示\n",
        "print(\"Forge WebUI 安装和更新完成。可以在 Google Drive 中找到并启动 WebUI。\")\n"
      ],
      "metadata": {
        "id": "RBmqVVYuOBWd",
        "outputId": "ed443ef1-e6e1-467c-eed7-16567c86fd77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "env: PYTHONDONTWRITEBYTECODE=1  # 防止写入 pyc 文件\n",
            "克隆 Forge WebUI 主程序...\n",
            "/content/stable-diffusion-webui 不是一个有效的 Git 仓库，准备克隆 stable-diffusion-webui-forge 仓库...\n",
            "克隆\n",
            "Forge WebUI 安装和更新完成。可以在 Google Drive 中找到并启动 WebUI。\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}